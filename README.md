# Ollash - Agente Local de IT Impulsado por Ollama

![Ollash Logo](Ollash.png)

Ollash es un agente de inteligencia artificial avanzado dise√±ado para asistir a desarrolladores y profesionales de IT. Aprovecha el poder de los Large Language Models (LLMs) ejecutados localmente a trav√©s de la plataforma [Ollama](https://ollama.ai/), permitiendo tanto interacci√≥n directa v√≠a CLI como la ejecuci√≥n aut√≥noma de tareas complejas como la generaci√≥n de proyectos completos de software.

Este proyecto se distingue por su arquitectura modular, alta mantenibilidad y una profunda observabilidad, fruto de una refactorizaci√≥n estrat√©gica para escalar y adaptarse a las demandas de un entorno de desarrollo en r√°pida evoluci√≥n.

---

## ‚úÖ Estado de Calidad

**Todas las pruebas unitarias est√°n pasando exitosamente:**

| M√©trica | Resultado |
|---------|-----------|
| **Tests Totales** | 468/468 ‚úÖ |
| **Tasa de √âxito** | 100% |
| **Tests Unitarios** | 331/331 ‚úÖ |
| **Tests de Integraci√≥n** | 137/137 ‚úÖ |
| **√öltima Ejecuci√≥n** | √âxita (0.02.2026) |

El proyecto ha alcanzado una cobertura completa de pruebas con √©nfasis en:
- Pruebas unitarias de componentes core (kernel, managers, servicios)
- Pruebas de integraci√≥n de agentes (DefaultAgent, AutoAgent, OllamaIntegration)
- Pruebas end-to-end de casos de uso complejos
- Validaci√≥n de configuraci√≥n y esquemas JSON

---

## üöÄ Arquitectura del Sistema (El Coraz√≥n de Ollash)

La arquitectura de Ollash ha sido meticulosamente redise√±ada para ofrecer una modularidad, extensibilidad y observabilidad excepcionales. En su n√∫cleo, encontramos el **Agent Kernel**, un *singleton* que centraliza la gesti√≥n de servicios globales y act√∫a como el pilar de la estabilidad del sistema.

### **Principios Arquitect√≥nicos Clave:**

*   **Desacoplamiento:** Los componentes interact√∫an a trav√©s de interfaces bien definidas, minimizando las dependencias impl√≠citas.
*   **Responsabilidad √önica (SRP):** Cada m√≥dulo tiene una funci√≥n clara y espec√≠fica.
*   **Extensibilidad:** Facilita la incorporaci√≥n de nuevas funcionalidades, LLMs o herramientas sin alterar el n√∫cleo.
*   **Observabilidad:** Proporciona una visi√≥n profunda del comportamiento del agente y las interacciones del LLM.

### **Componentes Centrales:**

1.  **Agent Kernel (`src/core/kernel.py`):**
    *   El coraz√≥n del sistema, implementado como un *singleton* para asegurar una √∫nica instancia global.
    *   **ConfigLoader:** Gestiona una configuraci√≥n modular y validada (ver m√°s abajo).
    *   **StructuredLogger:** Ofrece un sistema de logging JSON con `correlation_id` para trazabilidad de interacciones completas.
    *   Provee acceso centralizado a los servicios globales para todos los agentes.

2.  **Servicios Desacoplados:**
    *   **LLMClientManager (`src/services/llm_manager.py`):** Responsable de aprovisionar y gestionar instancias de `OllamaClient` para diferentes roles de LLM (ej. `coder`, `planner`), encapsulando la l√≥gica de selecci√≥n de modelos y aplicaci√≥n de *benchmarks*.
    *   **LLMRecorder (`src/utils/core/llm_recorder.py`):** Registra detalladamente cada interacci√≥n con Ollama, incluyendo prompts, respuestas, uso de tokens, latencia y modelo utilizado, facilitando el an√°lisis y debugging de decisiones del LLM.
    *   **ToolSpanManager (`src/utils/core/tool_span_manager.py`):** Implementa un sistema de "spans" para cada ejecuci√≥n de herramienta, registrando su duraci√≥n, √©xito/fallo y vincul√°ndolo al `correlation_id` global.

3.  **Interfaces (ABCs en `src/interfaces/`):**
    *   **`IModelProvider`:** Contrato para cualquier servicio que provea clientes de LLM, permitiendo su intercambio.
    *   **`IToolExecutor`:** Interfaz para la ejecuci√≥n de herramientas, desacoplando la l√≥gica de la herramienta de su invocaci√≥n.
    *   **`IMemorySystem`:** Define c√≥mo los agentes interact√∫an con el almacenamiento de memoria, ocultando los detalles de implementaci√≥n subyacentes.
    *   **`IAgentPhase`:** Contrato para cada etapa del pipeline del `AutoAgent`, garantizando una estructura uniforme y extensible.

---

## ‚ú® Caracter√≠sticas Principales

### **0. Phase 6: Sistema Avanzado de Notificaciones y Automatizaci√≥n**

**Phase 6** introduce un conjunto poderoso de componentes para mejorar la comunicaci√≥n, inteligencia y automatizaci√≥n del sistema:

#### **7 Nuevos Managers de N√∫cleo:**
- **AdaptiveNotificationUI**: Crea artefactos visuales interactivos (diagramas Mermaid, √°rboles de decisi√≥n, tarjetas de m√©tricas)
- **WebhookManager**: Env√≠a notificaciones a Slack, Discord, Teams y webhooks personalizados
- **ActivityReportGenerator**: Genera reportes diarios, an√°lisis de tendencias y detecci√≥n de anomal√≠as
- **VoiceCommandProcessor**: Convierte comandos de voz en acciones ejecutables
- **MemoryOfDecisions**: Registra decisiones y aprende de resultados para sugerencias inteligentes
- **FeedbackCycleManager**: Extrae preferencias de usuario del feedback para personalizaci√≥n
- **AdvancedTriggerManager**: Crea automatizaciones complejas con l√≥gica AND/OR/NOT/XOR

#### **REST API Completa:**
- 30+ endpoints para exponer toda la funcionalidad de Phase 6
- Integraci√≥n Flask lista para producci√≥n
- Soporte para operaciones por lotes y exportaci√≥n de datos

#### **Gu√≠as y Documentaci√≥n:**
- `PHASE_6_GETTING_STARTED.md`: Inicio r√°pido en 15 minutos
- `PHASE_6_API_INTEGRATION.md`: Referencia completa de API con ejemplos
- `PHASE_6_COMPLETION_SUMMARY.md`: Resumen t√©cnico detallado
- `FILE_STRUCTURE_PHASE6.md`: Gu√≠a de navegaci√≥n y arquitectura

**Uso:**
```python
from src.utils.core.webhook_manager import get_webhook_manager, WebhookType
from src.utils.core.voice_command_processor import get_voice_command_processor

# Enviar notificaci√≥n a Slack
webhooks = get_webhook_manager()
webhooks.register_webhook("slack", WebhookType.SLACK, "https://hooks.slack.com/...")
webhooks.send_to_webhook_sync(message="Alerta del sistema", title="‚ö†Ô∏è Status")

# Procesar comando de voz
voice = get_voice_command_processor()
command = voice.process_voice_input("crear tarea para ma√±ana")
```

---

### **1. Modo Interactivo: `DefaultAgent` (CLI Chat)**

El `DefaultAgent` proporciona una experiencia de chat interactiva en la l√≠nea de comandos, actuando como un asistente de IT con capacidades de "tool-calling" y una orquestaci√≥n inteligente.

*   **Chat basado en Mixins:** Su l√≥gica se descompone en *mixins* reutilizables:
    *   `IntentRoutingMixin`: Clasifica la intenci√≥n del usuario y selecciona el LLM m√°s adecuado para la tarea (ej. codificaci√≥n, planificaci√≥n, an√°lisis).
    *   `ToolLoopMixin`: Gestiona el bucle de ejecuci√≥n de herramientas, incluyendo "confirmation gates" para acciones que modifican el sistema y detecci√≥n de bucles infinitos.
    *   `ContextSummarizerMixin`: Maneja autom√°ticamente la ventana de contexto, resumiendo conversaciones extensas para mantener al LLM dentro de sus l√≠mites de tokens.
*   **Acceso a un amplio conjunto de herramientas:** El agente puede interactuar con el sistema de archivos, ejecutar comandos de terminal, gestionar repositorios Git, analizar c√≥digo, y m√°s.
*   **`Correlation ID`:** Cada interacci√≥n de chat genera un `correlation_id` √∫nico, permitiendo rastrear todas las operaciones relacionadas en los logs estructurados.

**Uso:**
```bash
python run_agent.py --chat
```

### **2. Modo Aut√≥nomo: `AutoAgent` (Generaci√≥n de Proyectos)**

El `AutoAgent` es un orquestador de proyectos que genera aplicaciones completas a partir de una descripci√≥n textual, siguiendo un pipeline de fases bien definido y auto-correctivo.

*   **Pipeline Modular de Fases:** El antiguo pipeline monol√≠tico de 8 fases se ha transformado en una secuencia de clases `IAgentPhase` independientes y reutilizables (ej. `ReadmeGenerationPhase`, `StructureGenerationPhase`, `FileContentGenerationPhase`, `TestGenerationExecutionPhase`, `SeniorReviewPhase`).
*   **`PhaseContext`:** Un objeto contextual que encapsula todas las dependencias (loggers, managers, LLMs) para cada fase, simplificando la inyecci√≥n de dependencias y el mantenimiento.
*   **Ciclos de Verificaci√≥n y Refinamiento:** Incluye fases de verificaci√≥n de c√≥digo, generaci√≥n y ejecuci√≥n de tests multi-idioma, y ciclos de mejora iterativa para corregir errores autom√°ticamente.
*   **Revisi√≥n de Estructura y Senior:** Incorpora revisiones automatizadas de la estructura inicial y una "revisi√≥n de senior" final para asegurar la calidad del proyecto generado.

**Uso:**
```bash
python auto_agent.py --description "Crea una aplicaci√≥n de lista de tareas con Flask y SQLite" --name task_manager --loops 1
```

### **3. Observabilidad Avanzada y Trazabilidad**

El sistema de observabilidad de Ollash ha sido dise√±ado para proporcionar una visibilidad sin precedentes en las operaciones del agente, facilitando el debugging y la auditor√≠a.

*   **Structured Logger (`src/utils/core/structured_logger.py`):**
    *   Todos los eventos del sistema se registran en formato JSON, lo que permite un an√°lisis program√°tico y f√°cil integraci√≥n con herramientas de monitoreo.
    *   **Correlation IDs:** Cada interacci√≥n de usuario o proceso aut√≥nomo genera un `correlation_id` que se propaga a todos los logs relacionados, permitiendo reconstruir el flujo completo de una operaci√≥n.
    *   **Rotaci√≥n de Logs:** Los logs se gestionan en la carpeta `logs/` con rotaci√≥n autom√°tica para evitar el llenado del disco.
*   **LLM Interaction Recorder (`src/utils/core/llm_recorder.py`):**
    *   Registra cada prompt enviado y cada respuesta recibida de los LLMs de Ollama.
    *   Captura m√©tricas cruciales como uso de tokens, modelo espec√≠fico, latencia y estado de √©xito/error.
*   **Tool Spans (`src/utils/core/tool_span_manager.py`):**
    *   Mide el tiempo de ejecuci√≥n de cada herramienta (`start_span`, `end_span`).
    *   Registra si la herramienta se ejecut√≥ con √©xito o fall√≥, proporcionando detalles relevantes en el log estructurado.

---

## üìÅ Estructura de Carpetas

La nueva organizaci√≥n del proyecto refleja la arquitectura modular, haciendo m√°s intuitivo para los desarrolladores localizar y contribuir a funcionalidades espec√≠ficas.

```
ollash/
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îú‚îÄ‚îÄ agent_features.json           # Configuraci√≥n de caracter√≠sticas y funcionalidades del agente
‚îÇ   ‚îú‚îÄ‚îÄ llm_models.json               # Asignaciones de modelos LLM y configuraciones de Ollama
‚îÇ   ‚îî‚îÄ‚îÄ tool_settings.json            # Configuraci√≥n de herramientas, logging y par√°metros operativos
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ agents/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ mixins/                   # Mixins reutilizables para DefaultAgent (IntentRouting, ToolLoop, ContextSummarizer)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ auto_agent_phases/        # Clases de fases independientes para el pipeline de AutoAgent
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...                       # DefaultAgent, AutoAgent y otros agentes
‚îÇ   ‚îú‚îÄ‚îÄ core/                         # Componentes fundamentales del Kernel (AgentKernel, ConfigSchemas, StructuredLogger, etc.)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config_schemas.py         # Definiciones de esquemas Pydantic para la configuraci√≥n
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ kernel.py                 # El Agent Kernel (singleton) y ConfigLoader
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ structured_logger.py      # Implementaci√≥n del logger estructurado con JSON y Correlation IDs
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...                       # Otros servicios core (file_manager, command_executor, etc.)
‚îÇ   ‚îú‚îÄ‚îÄ interfaces/                   # Definiciones de interfaces (ABCs) para desacoplamiento (IModelProvider, IToolExecutor, IMemorySystem, IAgentPhase)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ iagent_phase.py           # Interfaz para las fases del AutoAgent
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ imodel_provider.py        # Interfaz para proveedores de clientes LLM
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ imemory_system.py         # Interfaz para sistemas de memoria del agente
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ itool_executor.py         # Interfaz para ejecutores de herramientas
‚îÇ   ‚îú‚îÄ‚îÄ services/                     # Servicios especializados (LLMClientManager)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ llm_manager.py            # Gesti√≥n de clientes LLM
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ       ‚îú‚îÄ‚îÄ core/                     # Utilidades core existentes (agent_logger, ollama_client, llm_recorder, tool_span_manager, etc.)
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ agent_logger.py       # Wrapper sobre StructuredLogger
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ llm_recorder.py       # Registro detallado de interacciones LLM
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ tool_span_manager.py  # Gesti√≥n de Spans para ejecuci√≥n de herramientas
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ       ‚îî‚îÄ‚îÄ domains/                  # Implementaciones de herramientas y servicios por dominio
‚îÇ           ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ tests/
‚îî‚îÄ‚îÄ ...
```

---

## ‚öôÔ∏è Configuraci√≥n Modular y Validada

El sistema de configuraci√≥n ha sido completamente redise√±ado para mejorar la claridad, la validaci√≥n y la sobreescritura flexible.

*   **Archivos Fragmentados:** La configuraci√≥n monol√≠tica `settings.json` ha sido dividida en archivos espec√≠ficos por dominio en la carpeta `config/`:
    *   `llm_models.json`: Contiene todas las definiciones de modelos LLM, URLs de Ollama, timeouts y temperaturas.
    *   `agent_features.json`: Define las activaciones de caracter√≠sticas (feature flags) y configuraciones espec√≠ficas para funcionalidades como el grafo de conocimiento, el contexto de decisi√≥n, etc.
    *   `tool_settings.json`: Configura el nivel de sandboxing, l√≠mites de tokens, ajustes de logging, rutas de prompts por defecto y otros par√°metros operativos y de herramientas.
*   **Validaci√≥n de Esquemas (Pydantic):** Cada fragmento de configuraci√≥n es validado rigurosamente contra esquemas definidos con [Pydantic](https://pydantic-docs.helpmanual.io/). Esto asegura que la configuraci√≥n cargada sea siempre correcta, previniendo errores en tiempo de ejecuci√≥n debido a configuraciones mal formadas o incompletas.
*   **Carga Jer√°rquica y Sobreescritura:** El `ConfigLoader` en el `AgentKernel` es capaz de:
    1.  Cargar cada archivo de configuraci√≥n.
    2.  Fusionar las configuraciones.
    3.  Permitir la sobreescritura de cualquier valor de configuraci√≥n a trav√©s de variables de entorno (previamente definidas con el prefijo `OLLASH_`).

### **Ejemplo de Acceso a Configuraci√≥n:**

Los agentes y servicios ahora acceden a la configuraci√≥n de forma tipada y espec√≠fica a trav√©s del `AgentKernel`:

```python
# Desde un agente o servicio que tiene acceso al kernel
llm_config = self.kernel.get_llm_models_config()
tool_config = self.kernel.get_tool_settings_config()

print(f"URL de Ollama: {llm_config.ollama_url}")
print(f"Modelo por defecto: {llm_config.default_model}")
print(f"Nivel de Sandbox: {tool_config.sandbox_level}")
print(f"M√°ximas iteraciones: {tool_config.max_iterations}")

# Sobreescritura v√≠a variable de entorno:
# export OLLASH_LLM_MODELS_OLLAMA_URL="http://mi.ollama.server:8000"
# -> llm_config.ollama_url reflejar√≠a el valor de la variable de entorno.
```

---

## üõ†Ô∏è Gu√≠a de Extensibilidad

El dise√±o modular de Ollash facilita enormemente su extensi√≥n y adaptaci√≥n a nuevas necesidades.

### **A√±adir una Nueva Herramienta:**

1.  **Define la Herramienta:** Crea una nueva clase en `src/utils/domains/<new_domain>/<new_tool_set.py>` que contenga tus m√©todos de herramienta.
2.  **Registra la Herramienta:** Utiliza el decorador `@register_tool` para hacer que la herramienta sea descubrible por el `ToolRegistry`.
3.  **Implementa la L√≥gica:** Tus m√©todos de herramienta tendr√°n acceso al `AgentKernel` y a los servicios proporcionados a trav√©s de √©l (logger, configuraciones, etc.).
4.  **Actualiza `tool_settings.json`:** Si tu herramienta requiere configuraci√≥n espec√≠fica o nuevos permisos, a√±√°delos aqu√≠ y extienden el `ToolSettingsConfig` en `src/core/config_schemas.py` si es necesario.

### **Crear un Nuevo "Micro-Agent":**

1.  **Extiende `CoreAgent`:** Crea tu nuevo agente heredando de `src/agents/core_agent.py`.
2.  **Utiliza Mixins:** Aprovecha los mixins existentes (`IntentRoutingMixin`, `ToolLoopMixin`, `ContextSummarizerMixin`) para funcionalidades comunes y desarrolla nuevos mixins si es necesario.
3.  **Inyecta Dependencias:** Tu agente recibir√° `AgentKernel`, `LLMClientManager` y otros servicios esenciales a trav√©s de inyecci√≥n en su constructor, garantizando un bajo acoplamiento.
4.  **Define tu `run()` o `chat()`:** Implementa la l√≥gica espec√≠fica de tu micro-agente, orquestando las llamadas a LLMs y herramientas a trav√©s de las interfaces.

---

Este `README.md` es un reflejo de la robustez y el dise√±o reflexivo que subyacen en Ollash, prepar√°ndolo para un crecimiento continuo y una comunidad de desarrollo activa.
```