# Ollash Environment Configuration
# ----------------------------------
# This file contains all the configuration variables for the Ollash project.
# For complex settings, the entire JSON object is stored in a single environment variable.

# --- Core Settings (from settings.json) ---
OLLAMA_URL=http://192.168.1.217:11434
DEFAULT_MODEL=ministral-3:8b
DEFAULT_TIMEOUT=300
DEFAULT_TEMPERATURE=0.5
BENCHMARK_ENABLED=true

# --- JSON-based Configurations ---
# Each of these variables holds the content of the corresponding JSON file from the config/ directory.

AGENT_FEATURES_JSON='{"cross_reference": true, "knowledge_graph": {"auto_build": true, "max_depth": 3, "similarity_threshold": 0.6}, "decision_memory": {"auto_record": false, "save_on_shutdown": true, "retention_days": 365}, "artifacts": {"max_diagram_size": "1000x800", "supported_types": ["report", "diagram", "checklist", "code", "comparison"], "mermaid_theme": "default"}, "ocr": {"model": "deepseek-ocr:3b", "confidence_threshold": 0.7, "enabled": false}, "speech": {"enabled": false, "language": "es-ES", "max_duration_seconds": 60}}'

ALERTS_JSON='{"description": "Default alert thresholds and configurations for Ollash", "alerts": [{"alert_id": "high_cpu", "name": "High CPU Usage", "description": "System CPU usage is critically high", "severity": "critical", "entity": "cpu", "threshold": 85, "operator": ">", "cooldown_seconds": 600, "enabled": true, "channels": ["ui", "email"], "suggested_actions": ["Review running processes", "Check for resource leaks", "Consider stopping non-essential services"]}, {"alert_id": "high_memory", "name": "High Memory Usage", "description": "System memory usage is critically high", "severity": "critical", "entity": "memory", "threshold": 90, "operator": ">", "cooldown_seconds": 600, "enabled": true, "channels": ["ui", "email"], "suggested_actions": ["Identify memory-consuming processes", "Clear cache if available", "Restart heavy applications"]}, {"alert_id": "low_disk", "name": "Low Disk Space", "description": "Available disk space is below critical threshold", "severity": "critical", "entity": "disk", "threshold": 15, "operator": "<", "cooldown_seconds": 900, "enabled": true, "channels": ["ui", "email"], "suggested_actions": ["Delete old backups and unused files", "Archive old logs", "Clear temporary files", "Consider expanding storage"]}, {"alert_id": "moderate_cpu", "name": "Moderate CPU Usage", "description": "System CPU usage is elevated", "severity": "warning", "entity": "cpu", "threshold": 70, "operator": ">", "cooldown_seconds": 300, "enabled": true, "channels": ["ui"], "suggested_actions": ["Monitor system performance", "Check background processes"]}, {"alert_id": "moderate_memory", "name": "Moderate Memory Usage", "description": "System memory usage is elevated", "severity": "warning", "entity": "memory", "threshold": 75, "operator": ">", "cooldown_seconds": 300, "enabled": true, "channels": ["ui"], "suggested_actions": ["Monitor memory trends", "Prepare for potential optimization"]}, {"alert_id": "moderate_disk", "name": "Moderate Disk Usage", "description": "Available disk space is getting low", "severity": "warning", "entity": "disk", "threshold": 30, "operator": "<", "cooldown_seconds": 600, "enabled": true, "channels": ["ui"], "suggested_actions": ["Plan cleanup soon", "Monitor disk usage trends"]}, {"alert_id": "model_timeout", "name": "Model Response Timeout", "description": "Model failed to respond within expected time", "severity": "warning", "entity": "model", "threshold": 5000, "operator": ">", "cooldown_seconds": 300, "enabled": true, "channels": ["ui", "log"], "suggested_actions": ["Check model service status", "Verify network connectivity", "Try again or select different model"]}, {"alert_id": "too_many_errors", "name": "High Error Rate", "description": "Too many errors detected in recent operations", "severity": "warning", "entity": "system", "threshold": 10, "operator": ">", "cooldown_seconds": 900, "enabled": true, "channels": ["ui", "log"], "suggested_actions": ["Review recent error logs", "Check system health", "Verify all services are running"]}], "alert_channels": {"ui": {"enabled": true, "description": "Real-time notifications in the web interface", "show_sound": true, "auto_dismiss_ms": 5000}, "email": {"enabled": false, "description": "Email notifications for critical alerts", "requires_config": true, "min_severity": "critical"}, "log": {"enabled": true, "description": "Write alerts to system logs", "min_severity": "warning"}}}'

AUTO_BENCHMARK_TASKS_JSON='[{"name": "Generar Aplicaci\u00f3n Web Simple", "description": "Crea una aplicaci\u00f3n web simple en Python (Flask o Django) que muestre un ''Hola Mundo'' y una ruta `/info` que muestre la fecha y hora actual.", "type": "web_app", "difficulty": "basic", "time_limit_minutes": 5}, {"name": "Generar Herramienta CLI", "description": "Desarrolla una herramienta de l\u00ednea de comandos en Python que tome una ruta de archivo como argumento y cuente el n\u00famero de l\u00edneas y palabras en ese archivo. Debe manejar errores si el archivo no existe.", "type": "cli_tool", "difficulty": "intermediate", "time_limit_minutes": 5}, {"name": "Generar Juego Simple", "description": "Crea un juego simple de ''Adivina el N\u00famero'' en Python. La computadora elige un n\u00famero aleatorio y el usuario tiene 5 intentos para adivinarlo, recibiendo pistas de ''m\u00e1s alto'' o ''m\u00e1s bajo''.", "type": "game_simple", "difficulty": "intermediate", "time_limit_minutes": 5}, {"name": "Generar Script de Procesamiento de Datos", "description": "Escribe un script en Python que lea un archivo CSV con columnas ''nombre'', ''edad'', ''ciudad''. El script debe filtrar las personas mayores de 30 a\u00f1os y guardar los resultados en un nuevo archivo CSV.", "type": "data_script", "difficulty": "intermediate", "time_limit_minutes": 5}, {"name": "Generar Herramienta de Utilidad de Archivos", "description": "Desarrolla una herramienta en Python que pueda listar todos los archivos en un directorio dado y sus tama\u00f1os en MB. Debe ser capaz de recibir la ruta del directorio como argumento de l\u00ednea de comandos.", "type": "utility_tool", "difficulty": "basic", "time_limit_minutes": 5}]'

AUTOMATION_TEMPLATES_JSON='{"example_triggers": [{"trigger_id": "cpu_usage_high", "name": "High CPU Usage Alert", "description": "Alert when CPU exceeds 80% for system optimization", "rule": {"conditions": [{"metric": "system.cpu_usage", "operator": ">", "value": 80}], "logic": "AND"}, "actions": [{"type": "send_notification", "title": "\u26a0\ufe0f High CPU Usage", "message": "CPU usage has exceeded 80%. Review active processes.", "severity": "warning"}, {"type": "execute_prompt", "name": "CPU Analysis", "agent": "system", "prompt": "Identify top 5 processes consuming the most CPU and suggest optimizations"}]}, {"trigger_id": "memory_pressure", "name": "Memory Pressure Alert", "description": "Alert when available memory drops below 20%", "rule": {"conditions": [{"metric": "system.memory_free_percent", "operator": "<", "value": 20}], "logic": "AND"}, "actions": [{"type": "send_notification", "title": "\ud83d\udd34 Memory Pressure", "message": "Available memory is below 20%. Consider freeing resources.", "severity": "critical"}, {"type": "execute_prompt", "name": "Memory Cleanup", "agent": "system", "prompt": "Identify memory leaks and suggest cleanup procedures"}]}, {"trigger_id": "disk_space_low", "name": "Low Disk Space Alert", "description": "Alert when disk space falls below 15%", "rule": {"conditions": [{"metric": "system.disk_free_percent", "operator": "<", "value": 15}], "logic": "AND"}, "actions": [{"type": "send_notification", "title": "\ud83d\udd34 Low Disk Space", "message": "Available disk space is critically low.", "severity": "critical"}, {"type": "execute_prompt", "name": "Disk Cleanup", "agent": "system", "prompt": "Find large files and directories. Identify cache/temp files that can be safely deleted."}]}, {"trigger_id": "service_down", "name": "Critical Service Down", "description": "Alert when a critical service becomes unavailable", "rule": {"conditions": [{"metric": "network.service_status", "operator": "==", "value": "DOWN"}], "logic": "AND"}, "actions": [{"type": "send_notification", "title": "\ud83d\udd34 SERVICE DOWN", "message": "A critical service is unavailable. Emergency response initiated.", "severity": "critical"}, {"type": "execute_prompt", "name": "Emergency Remediation", "agent": "network", "prompt": "Analyze service failure, check logs, and provide recovery steps"}]}, {"trigger_id": "security_threat", "name": "Security Threat Detected", "description": "Alert when security scan detects issues", "rule": {"conditions": [{"metric": "security.threat_level", "operator": ">", "value": 5}], "logic": "AND"}, "actions": [{"type": "send_notification", "title": "\ud83d\udee1\ufe0f SECURITY ALERT", "message": "Security threat detected. Review immediately.", "severity": "critical"}, {"type": "execute_prompt", "name": "Security Response", "agent": "cybersecurity", "prompt": "Analyze security threat, check logs, and recommend remediation"}]}, {"trigger_id": "api_latency_high", "name": "High API Latency", "description": "Alert when API response time exceeds 2 seconds", "rule": {"conditions": [{"metric": "network.api_latency_ms", "operator": ">", "value": 2000}], "logic": "AND"}, "actions": [{"type": "send_notification", "title": "\u26a0\ufe0f High API Latency", "message": "API response time is degraded. Performance issue detected.", "severity": "warning"}]}, {"trigger_id": "failed_auth_spike", "name": "Failed Authentication Spike", "description": "Alert on unusual spike in failed authentication attempts", "rule": {"conditions": [{"metric": "security.failed_auth_count", "operator": ">", "value": 10}], "logic": "AND"}, "actions": [{"type": "send_notification", "title": "\ud83d\udd12 AUTH SPIKE", "message": "Unusual spike in failed authentication attempts detected.", "severity": "critical"}, {"type": "execute_prompt", "name": "Security Investigation", "agent": "cybersecurity", "prompt": "Analyze failed auth attempts, identify sources, check for brute force attacks"}]}], "example_automations": [{"name": "Daily System Health Check", "description": "Complete system health check every morning at 8 AM", "agent": "system", "prompt": "Perform comprehensive system check including CPU, memory, disk, processes, and system logs. Report any issues found.", "schedule": "daily", "cron": "0 8 * * *", "notifyEmail": true}, {"name": "Hourly Uptime Check", "description": "Check critical services every hour", "agent": "network", "prompt": "Ping critical services (8.8.8.8, 1.1.1.1) and verify API endpoints are responding. Report any issues.", "schedule": "hourly", "notifyEmail": false}, {"name": "Weekly Security Scan", "description": "Comprehensive security audit every Sunday at 2 AM", "agent": "cybersecurity", "prompt": "Run full security scan: check file integrity, analyze security logs, scan for vulnerabilities, verify permissions.", "schedule": "weekly", "cron": "0 2 * * 0", "notifyEmail": true}, {"name": "Log Analysis - Daily", "description": "Analyze system and application logs daily", "agent": "system", "prompt": "Analyze all available logs from the past 24 hours. Identify errors, warnings, and anomalies.", "schedule": "daily", "cron": "0 22 * * *", "notifyEmail": true}, {"name": "Port Monitoring", "description": "Check critical ports status every 30 minutes", "agent": "network", "prompt": "Check status of ports: 80, 443, 22, 3306, 5432, 8080. Report any changes.", "schedule": "custom", "notifyEmail": false}, {"name": "Dependency Update Check", "description": "Check for outdated packages weekly", "agent": "system", "prompt": "Check for outdated Python packages, npm packages, and system libraries. Provide update recommendations.", "schedule": "weekly", "cron": "0 10 * * 1", "notifyEmail": true}], "trigger_examples_by_category": {"system": [{"metric": "system.cpu_usage", "threshold": 80, "operator": ">", "action": "Alert and analyze top processes"}, {"metric": "system.memory_free_percent", "threshold": 20, "operator": "<", "action": "Alert and suggest memory cleanup"}, {"metric": "system.disk_free_percent", "threshold": 15, "operator": "<", "action": "Alert and find large files"}], "network": [{"metric": "network.uptime_percent", "threshold": 99.5, "operator": "<", "action": "Alert on degraded uptime"}, {"metric": "network.api_latency_ms", "threshold": 2000, "operator": ">", "action": "Alert on performance degradation"}, {"metric": "network.packet_loss_percent", "threshold": 1, "operator": ">", "action": "Alert on network issues"}], "security": [{"metric": "security.failed_auth_count", "threshold": 10, "operator": ">", "action": "Alert on brute force attempt"}, {"metric": "security.vulnerability_count", "threshold": 0, "operator": ">", "action": "Alert on vulnerabilities found"}, {"metric": "security.integrity_status", "threshold": "OK", "operator": "!=", "action": "Alert on unauthorized file changes"}]}}'

BENCHMARK_TASKS_EXTENDED_JSON='{"phase_categories": {"reasoning_architecture": {"description": "Fases que requieren razonamiento arquitect\u00f3nico profundo", "phases": ["ProjectAnalysisPhase", "ReadmeGenerationPhase", "StructureGenerationPhase", "LogicPlanningPhase", "StructurePreReviewPhase"]}, "high_fidelity_code_generation": {"description": "Fases de generaci\u00f3n de c\u00f3digo con alta precisi\u00f3n", "phases": ["EmptyFileScaffoldingPhase", "FileContentGenerationPhase", "FileRefinementPhase", "DependencyReconciliationPhase", "TestGenerationExecutionPhase", "ExhaustiveReviewRepairPhase"]}, "validation_and_critique": {"description": "Fases de validaci\u00f3n, cr\u00edtica y cumplimiento", "phases": ["VerificationPhase", "CodeQuarantinePhase", "LicenseCompliancePhase", "FinalReviewPhase", "IterativeImprovementPhase", "ContentCompletenessPhase", "SeniorReviewPhase"]}}, "benchmark_tasks": [{"id": "arch_01", "category": "reasoning_architecture", "phase": "LogicPlanningPhase", "difficulty": "advanced", "type": "logic_plan_validation", "name": "Validaci\u00f3n de Plan L\u00f3gico vs C\u00f3digo Final", "description": "El modelo debe generar un plan l\u00f3gico detallado para una aplicaci\u00f3n web con autenticaci\u00f3n. Luego, el benchmark verifica si todas las funciones y servicios descritos en el plan fueron realmente implementados en el c\u00f3digo final sin alucinaciones.", "success_criteria": ["Todas las funciones listadas en logic_plan existen en el c\u00f3digo", "Los nombres de funciones coinciden exactamente", "Las dependencias del plan se reflejan en requirement.txt", "No hay funciones alucinadas (mencionadas pero no implementadas)"], "metrics": ["hallucination_ratio", "plan_coverage", "function_match_accuracy"], "sample_input": {"project_type": "web_app", "requirements": "Build a Flask app with user authentication, JWT tokens, and SQLite database", "modules_expected": ["auth", "database", "api", "utils"]}}, {"id": "arch_02", "category": "reasoning_architecture", "phase": "StructureGenerationPhase", "difficulty": "advanced", "type": "architecture_planning", "name": "Generaci\u00f3n de Estructura Modular Balanceada", "description": "Genera una estructura de proyecto para una aplicaci\u00f3n mediana (12-15 m\u00f3dulos) sin crear directorios superfluos o profundidad excesiva. Valida que la estructura sea navegable.", "success_criteria": ["Max 5 niveles de profundidad", "Cada directorio contiene 2-8 archivos", "Sin carpetas vac\u00edas", "Nombres auto-descriptivos"], "metrics": ["structure_balance_score", "modularity_index", "depth_penalty"]}, {"id": "arch_03", "category": "reasoning_architecture", "phase": "StructurePreReviewPhase", "difficulty": "extreme", "type": "circular_dependency_detection", "name": "Detecci\u00f3n y Resoluci\u00f3n de Dependencias Circulares", "description": "Presenta una estructura de proyecto con dependencias circulares. El modelo debe identificarlas y proponer una reestructuraci\u00f3n que las resuelva sin eliminar funcionalidad.", "success_criteria": ["Detecta todas las dependencias circulares", "La soluci\u00f3n propuesta es v\u00e1lida", "No se pierde funcionalidad", "La nueva estructura es mejor o igual en modularidad"], "metrics": ["circular_dep_detection_rate", "resolution_validity"], "sample_input": {"problematic_structure": {"module_a": ["imports module_b"], "module_b": ["imports module_c"], "module_c": ["imports module_a"]}}}, {"id": "code_01", "category": "high_fidelity_code_generation", "phase": "FileContentGenerationPhase", "difficulty": "advanced", "type": "context_aware_generation", "name": "Generaci\u00f3n de C\u00f3digo Consciente del Contexto", "description": "Genera un archivo principal (main.py) que depende de 5 m\u00f3dulos diferentes. El modelo debe mantener consistencia de tipos, imports correctos y patrones de uso coherentes con los m\u00f3dulos existentes.", "success_criteria": ["Todos los imports son v\u00e1lidos", "Las funciones llamadas existen en m\u00f3dulos importados", "Los tipos de par\u00e1metros coinciden", "No hay c\u00f3digo muerto"], "metrics": ["import_validity_ratio", "function_signature_match", "consistency_score"]}, {"id": "code_02", "category": "high_fidelity_code_generation", "phase": "ExhaustiveReviewRepairPhase", "difficulty": "extreme", "type": "repair_efficiency", "name": "Eficacia de Reparaci\u00f3n en Un Intento", "description": "El benchmark inyecta deliberadamente 10 errores comunes en el c\u00f3digo (importes faltantes, tipos inv\u00e1lidos, funciones ausentes). El modelo debe identificar y reparar el m\u00e1ximo n\u00famero en una sola iteraci\u00f3n.", "success_criteria": ["Identifica 90%+ de los errores inyectados", "Las reparaciones no introducen nuevos bugs", "El c\u00f3digo corregido pasa linting", "Mantiene la estructura original"], "metrics": ["error_detection_rate", "single_pass_fix_rate", "new_bug_introduction_rate"], "injected_errors": ["Missing import statement", "Undefined variable reference", "Type mismatch in function call", "Missing required parameter", "Incorrect indentation", "Syntax error in f-string", "Missing return statement", "Unreachable code", "Deprecated API usage", "Logic error in loop condition"]}, {"id": "code_03", "category": "high_fidelity_code_generation", "phase": "FileRefinementPhase", "difficulty": "advanced", "type": "fragment_cache_effectiveness", "name": "Efectividad de Reutilizaci\u00f3n de Fragmentos (FragmentCache)", "description": "El modelo debe generar 3 archivos relacionados. Mide cu\u00e1ntos fragmentos del FragmentCache se reutilizan correctamente sin duplicaci\u00f3n innecesaria.", "success_criteria": ["Reutiliza 70%+ de fragmentos aplicables", "No duplica c\u00f3digo id\u00e9ntico", "Respeta l\u00edmites sem\u00e1nticos de fragmentos", "Tokens ahorrados vs regeneraci\u00f3n"], "metrics": ["fragment_reuse_ratio", "token_savings", "semantic_boundary_respect"]}, {"id": "validate_01", "category": "validation_and_critique", "phase": "VerificationPhase", "difficulty": "intermediate", "type": "basic_validation", "name": "Validaci\u00f3n B\u00e1sica de Integridad", "description": "Verifica que todo archivo generado sea sint\u00e1cticamente correcto y que los imports referencias existan realmente.", "success_criteria": ["Todas las l\u00edneas de sintaxis son v\u00e1lidas", "Los imports referenciados existen", "No hay archivos truncados", "Encoding es correcto"], "metrics": ["syntax_error_count", "import_validity_ratio", "file_integrity_score"]}, {"id": "validate_02", "category": "validation_and_critique", "phase": "LicenseCompliancePhase", "difficulty": "intermediate", "type": "license_detection", "name": "Detecci\u00f3n de Cumplimiento de Licencias", "description": "Verifica que el proyecto incluye archivos LICENSE.md/LICENSE.txt, headers SPDX en archivos cr\u00edticos, y que las dependencias son compatibles con la licencia del proyecto.", "success_criteria": ["Existe archivo LICENSE", "Contiene texto v\u00e1lido de licencia seleccionada", "Archivos principales tienen header SPDX", "Dependencias son compatibles"], "metrics": ["license_file_presence", "spdx_header_coverage", "dependency_compatibility_ratio"]}, {"id": "validate_03", "category": "validation_and_critique", "phase": "DependencyReconciliationPhase", "difficulty": "advanced", "type": "rag_context_effectiveness", "name": "Efectividad de RAGContextSelector", "description": "El benchmark inyecta 15 archivos en el proyecto, de los cuales solo 5 son realmente relevantes para una tarea espec\u00edfica. Mide si RAGContextSelector recupera correctamente los archivos relevantes que el LLM realmente usar\u00eda.", "success_criteria": ["Recupera 4/5 archivos relevantes (80%+ recall)", "Filtra 80%+ de archivos irrelevantes", "Precision >= 80%", "Orden de relevancia es correcto"], "metrics": ["rag_recall_score", "rag_precision_score", "ranking_accuracy"], "sample_input": {"total_files": 15, "relevant_files": 5, "task": "Implementar endpoint REST para autenticaci\u00f3n", "file_types": ["auth", "api", "database", "utils", "tests", "config"]}}, {"id": "validate_04", "category": "validation_and_critique", "phase": "SeniorReviewPhase", "difficulty": "extreme", "type": "critical_error_detection", "name": "Detecci\u00f3n de Errores Cr\u00edticos en Senior Review", "description": "El modelo act\u00faa como revisor cr\u00edtico. Se le presenta c\u00f3digo que ha pasado todas las fases anteriores pero contiene 3-5 errores l\u00f3gicos sutiles y 2-3 violaciones de mejores pr\u00e1cticas. Debe detectarlos sin simplemente dar el visto bueno.", "success_criteria": ["Detecta 80%+ de errores sutiles", "Propone soluciones v\u00e1lidas", "No aprueba c\u00f3digo con issues", "Sugiere mejoras accionables"], "metrics": ["subtle_error_detection_rate", "fake_approval_penalty", "improvement_suggestion_quality"], "embedded_issues": [{"type": "logic_error", "severity": "high", "description": "Ãndice off-by-one en iteraci\u00f3n de lista"}, {"type": "logic_error", "severity": "high", "description": "Condici\u00f3n nula nunca se ejecuta (unreachable)"}, {"type": "race_condition", "severity": "critical", "description": "Acceso concurrente a variable global", "requires_code_review": true}, {"type": "best_practice", "severity": "medium", "description": "Funci\u00f3n muy larga (>50 l\u00edneas sin documentaci\u00f3n)"}, {"type": "best_practice", "severity": "medium", "description": "Manejo de excepciones demasiado gen\u00e9rico (catch Exception)"}]}], "phase_metrics_mapping": {"ProjectAnalysisPhase": ["analysis_accuracy", "dependency_discovery_rate"], "ReadmeGenerationPhase": ["clarity_score", "requirement_coverage"], "StructureGenerationPhase": ["modularity_score", "navigation_ease"], "LogicPlanningPhase": ["hallucination_ratio", "plan_coverage", "function_match_accuracy"], "StructurePreReviewPhase": ["circular_dep_detection_rate", "resolution_validity"], "EmptyFileScaffoldingPhase": ["skeleton_completeness", "import_validity_ratio"], "FileContentGenerationPhase": ["consistency_score", "context_awareness"], "FileRefinementPhase": ["fragment_reuse_ratio", "token_savings"], "VerificationPhase": ["syntax_error_count", "file_integrity_score"], "CodeQuarantinePhase": ["problematic_code_isolation", "false_positive_rate"], "LicenseCompliancePhase": ["license_coverage", "dependency_compatibility_ratio"], "DependencyReconciliationPhase": ["rag_recall_score", "rag_precision_score"], "TestGenerationExecutionPhase": ["test_coverage", "test_pass_rate"], "ExhaustiveReviewRepairPhase": ["error_detection_rate", "single_pass_fix_rate"], "FinalReviewPhase": ["issue_identification_rate", "solution_validity"], "IterativeImprovementPhase": ["improvement_quality", "iteration_convergence"], "ContentCompletenessPhase": ["completeness_score", "missing_component_detection"], "SeniorReviewPhase": ["subtle_error_detection_rate", "fake_approval_penalty"]}}'

BENCHMARK_TASKS_JSON='[{"difficulty": "basic", "type": "code_generation", "task": "Write a Python function called `is_palindrome` that checks if a given string is a palindrome, ignoring case and spaces."}, {"difficulty": "basic", "type": "reasoning", "task": "Explain the difference between a list and a tuple in Python. When would you use each one?"}, {"difficulty": "intermediate", "type": "code_analysis", "task": "Find all bugs in this Python code and explain each one:\n\ndef merge_sorted(a, b):\n    result = []\n    i = j = 0\n    while i < len(a) and j < len(b):\n        if a[i] <= b[j]:\n            result.append(a[i])\n            i += 1\n        else:\n            result.append(b[j])\n            j += 1\n    return result"}, {"difficulty": "intermediate", "type": "reasoning_architecture", "task": "Identify all dependencies between the `OllamaClient`, `DefaultAgent`, and `TokenTracker` classes and explain how information flows between them."}, {"difficulty": "intermediate", "type": "tool_integration", "task": "Write a Python class `ConfigValidator` that takes a JSON config file path, loads it, validates that all required fields (''model'', ''url'', ''timeout'') are present and have correct types (str, str, int), and returns a list of validation errors."}, {"difficulty": "advanced", "type": "technical_content_generation", "task": "Design and implement a Python retry decorator that supports: exponential backoff with jitter, configurable max retries, a list of retryable exception types, and an optional circuit breaker that stops retrying after N consecutive failures across calls."}, {"difficulty": "advanced", "type": "security_sandbox", "task": "Review this Python code for security vulnerabilities and explain each issue:\n\nimport os, sqlite3, subprocess\n\ndef handle_request(user_input):\n    conn = sqlite3.connect(''app.db'')\n    cursor = conn.execute(f\"SELECT * FROM users WHERE name = ''{user_input}''\")\n    result = cursor.fetchall()\n    \n    log_path = os.path.join(''/var/log/app'', user_input + ''.log'')\n    with open(log_path, ''r'') as f:\n        logs = f.read()\n    \n    output = subprocess.check_output(f''grep {user_input} /var/log/syslog'', shell=True)\n    return {''users'': result, ''logs'': logs, ''syslog'': output}"}, {"difficulty": "advanced", "type": "logic_edge_cases", "task": "Identify all race conditions, deadlocks, and edge cases in this code:\n\nimport threading\n\nclass BoundedBuffer:\n    def __init__(self, size):\n        self.buffer = []\n        self.size = size\n        self.lock = threading.Lock()\n        self.not_full = threading.Condition(self.lock)\n        self.not_empty = threading.Condition(self.lock)\n    \n    def put(self, item):\n        with self.not_full:\n            while len(self.buffer) >= self.size:\n                self.not_full.wait()\n            self.buffer.append(item)\n            self.not_empty.notify()\n    \n    def get(self):\n        with self.not_empty:\n            while len(self.buffer) == 0:\n                self.not_empty.wait()\n            item = self.buffer.pop(0)\n            self.not_full.notify()\n            return item\n    \n    def peek_and_get(self):\n        item = self.buffer[0]  # peek without lock\n        return self.get()"}, {"difficulty": "extreme", "type": "architecture_design", "task": "Design a plugin system for a Python CLI tool. Requirements: 1) Plugins are discovered from a configurable directory. 2) Each plugin declares dependencies on other plugins. 3) Plugins are loaded lazily on first use. 4) Circular dependencies must be detected and reported. 5) Plugins run in a restricted sandbox (no filesystem writes outside a temp dir, no network access). Provide the full implementation with classes, interfaces, and a dependency resolver."}, {"difficulty": "extreme", "type": "autonomous_flow", "task": "You are given a legacy Flask application with these issues: mixed Python 2/3 syntax, SQL queries built with string concatenation, no input validation, credentials hardcoded in source, no tests, and circular imports between 5 modules. Create a complete, prioritized remediation plan with: 1) Dependency graph of the circular imports and how to break them. 2) A migration script skeleton for Python 2 to 3 compatibility. 3) A parameterized query migration strategy. 4) An input validation layer design. 5) A secrets management approach. 6) A test strategy covering critical paths first. Provide concrete code examples for each step."}]'

LLM_MODELS_JSON='{"ollama_url": "http://192.168.1.217:11434", "default_model": "ministral-3:8b", "default_timeout": 300, "default_temperature": 0.5, "models": {"coding": "qwen3-coder-next", "reasoning": "gpt-oss:20b", "orchestration": "ministral-3:8b", "summarization": "ministral-3:8b", "self_correction": "ministral-3:8b", "embedding": "qwen3-embedding:4b", "prototyper_model": "gpt-oss:20b", "coder_model": "qwen3-coder:30b", "planner_model": "ministral-3:14b", "generalist_model": "ministral-3:8b", "suggester_model": "ministral-3:8b", "improvement_planner_model": "ministral-3:14b", "senior_reviewer_model": "ministral-3:8b"}, "model_timeouts": {"prototyper_timeout": 600, "coder_timeout": 480, "planner_timeout": 900, "generalist_timeout": 300, "suggester_timeout": 300, "improvement_planner_timeout": 900, "senior_reviewer_timeout": 600}, "model_capabilities": {"qwen3-coder-next": {"type": "local_open", "capability_level": "high", "specialization": ["code_generation", "code_refinement"], "context_window": 8192, "fallback_priority": 2}, "gpt-oss:20b": {"type": "local_open", "capability_level": "expert", "specialization": ["reasoning", "planning", "logic"], "context_window": 4096, "fallback_priority": 2}, "qwen3-coder:30b": {"type": "local_open", "capability_level": "expert", "specialization": ["code_generation", "complex_refactoring"], "context_window": 8192, "fallback_priority": 1}, "ministral-3:14b": {"type": "local_open", "capability_level": "high", "specialization": ["planning", "instruction_following"], "context_window": 8192, "fallback_priority": 2}, "ministral-3:8b": {"type": "local_open", "capability_level": "medium", "specialization": ["orchestration", "quick_analysis"], "context_window": 8192, "fallback_priority": 3}}, "rescue_models": {"senior_reviewer": "gpt-oss:70b", "coder_model": "qwen3-coder:30b", "planner_model": "gpt-oss:20b", "prototyper_model": "gpt-oss:20b"}, "phase_critical_thresholds": {"SeniorReviewPhase": {"min_success_rate": 0.85, "activates_rescue": true, "criticality": 1.0}, "LogicPlanningPhase": {"min_success_rate": 0.80, "activates_rescue": true, "criticality": 0.9}, "ExhaustiveReviewRepairPhase": {"min_success_rate": 0.75, "activates_rescue": true, "criticality": 0.8}, "FileContentGenerationPhase": {"min_success_rate": 0.70, "activates_rescue": false, "criticality": 0.7}, "StructurePreReviewPhase": {"min_success_rate": 0.75, "activates_rescue": true, "criticality": 0.8}}, "dynamic_routing_config": {"enabled": true, "benchmark_based_selection": true, "auto_rescue_activation": true, "rescue_threshold_success_rate": 0.65, "max_rescue_escalations": 2, "log_routing_decisions": true}}'

TASKS_JSON='[{"difficulty": "basic", "type": "code_generation", "task": "Write a Python function called `is_palindrome` that checks if a given string is a palindrome, ignoring case and spaces."}, {"difficulty": "basic", "type": "reasoning", "task": "Explain the difference between a list and a tuple in Python. When would you use each one?"}, {"difficulty": "intermediate", "type": "code_analysis", "task": "Find all bugs in this Python code and explain each one:\n\ndef merge_sorted(a, b):\n    result = []\n    i = j = 0\n    while i < len(a) and j < len(b):\n        if a[i] <= b[j]:\n            result.append(a[i])\n            i += 1\n        else:\n            result.append(b[j])\n            j += 1\n    return result"}, {"difficulty": "intermediate", "type": "reasoning_architecture", "task": "Identify all dependencies between the `OllamaClient`, `DefaultAgent`, and `TokenTracker` classes and explain how information flows between them."}, {"difficulty": "intermediate", "type": "tool_integration", "task": "Write a Python class `ConfigValidator` that takes a JSON config file path, loads it, validates that all required fields (''model'', ''url'', ''timeout'') are present and have correct types (str, str, int), and returns a list of validation errors."}, {"difficulty": "advanced", "type": "technical_content_generation", "task": "Design and implement a Python retry decorator that supports: exponential backoff with jitter, configurable max retries, a list of retryable exception types, and an optional circuit breaker that stops retrying after N consecutive failures across calls."}, {"difficulty": "advanced", "type": "security_sandbox", "task": "Review this Python code for security vulnerabilities and explain each issue:\n\nimport os, sqlite3, subprocess\n\ndef handle_request(user_input):\n    conn = sqlite3.connect(''app.db'')\n    cursor = conn.execute(f\"SELECT * FROM users WHERE name = ''{user_input}''\")\n    result = cursor.fetchall()\n    \n    log_path = os.path.join(''/var/log/app'', user_input + ''.log'')\n    with open(log_path, ''r'') as f:\n        logs = f.read()\n    \n    output = subprocess.check_output(f''grep {user_input} /var/log/syslog'', shell=True)\n    return {''users'': result, ''logs'': logs, ''syslog'': output}"}, {"difficulty": "advanced", "type": "logic_edge_cases", "task": "Identify all race conditions, deadlocks, and edge cases in this code:\n\nimport threading\n\nclass BoundedBuffer:\n    def __init__(self, size):\n        self.buffer = []\n        self.size = size\n        self.lock = threading.Lock()\n        self.not_full = threading.Condition(self.lock)\n        self.not_empty = threading.Condition(self.lock)\n    \n    def put(self, item):\n        with self.not_full:\n            while len(self.buffer) >= self.size:\n                self.not_full.wait()\n            self.buffer.append(item)\n            self.not_empty.notify()\n    \n    def get(self):\n        with self.not_empty:\n            while len(self.buffer) == 0:\n                self.not_empty.wait()\n            item = self.buffer.pop(0)\n            self.not_full.notify()\n            return item\n    \n    def peek_and_get(self):\n        item = self.buffer[0]  # peek without lock\n        return self.get()"}, {"difficulty": "extreme", "type": "architecture_design", "task": "Design a plugin system for a Python CLI tool. Requirements: 1) Plugins are discovered from a configurable directory. 2) Each plugin declares dependencies on other plugins. 3) Plugins are loaded lazily on first use. 4) Circular dependencies must be detected and reported. 5) Plugins run in a restricted sandbox (no filesystem writes outside a temp dir, no network access). Provide the full implementation with classes, interfaces, and a dependency resolver."}, {"difficulty": "extreme", "type": "autonomous_flow", "task": "You are given a legacy Flask application with these issues: mixed Python 2/3 syntax, SQL queries built with string concatenation, no input validation, credentials hardcoded in source, no tests, and circular imports between 5 modules. Create a complete, prioritized remediation plan with: 1) Dependency graph of the circular imports and how to break them. 2) A migration script skeleton for Python 2 to 3 compatibility. 3) A parameterized query migration strategy. 4) An input validation layer design. 5) A secrets management approach. 6) A test strategy covering critical paths first. Provide concrete code examples for each step."}]'

TOOL_SETTINGS_JSON='{"sandbox": "limited", "max_context_tokens": 4096, "summarize_threshold_ratio": 0.7, "history_limit": 20, "log_level": "debug", "log_file": "ollash.log", "log_format": "%(asctime)s - %(name)s - %(levelname)s - %(message)s", "default_system_prompt_path": "prompts/orchestrator/default_orchestrator.json", "use_docker_sandbox": false, "rate_limiting": {"requests_per_minute": 60, "max_tokens_per_minute": 100000}, "gpu_rate_limiter": {"degradation_threshold_ms": 5000.0, "recovery_threshold_ms": 2000.0, "min_rpm": 5, "ema_alpha": 0.3}, "auto_confirm_tools": false, "max_iterations": 30, "loop_detection_threshold": 3, "semantic_similarity_threshold": 0.95, "parallel_generation_max_concurrent": 3, "parallel_generation_max_rpm": 10, "senior_review_max_attempts": 3, "completeness_checker_max_retries": 2, "token_encoding_name": "cl100k_base"}'
